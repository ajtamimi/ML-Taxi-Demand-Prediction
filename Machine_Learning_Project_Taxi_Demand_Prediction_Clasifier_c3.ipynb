{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  ..........     Taxi Demand Prediction - New York City     ................"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ............      ML Course Project/Real-World Problem      ............"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Acknowledgments\n",
    "\n",
    "We would like to thank our supervisor Dr. Hashim Tamimi for providing valuable input and supporting us during this semester.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Supervisor: \n",
    "   * Dr. Hashim Tamimi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Project Team :\n",
    "    1- Eng. Baha' Abu-Qarandal (ID:176035)\n",
    "    2- Eng. Alaa  Tamimi       (ID:196206)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1 - Introduction:\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Project Goal:\n",
    "\n",
    "Taxis are a part of the transportation system of most cities and provide a service to take individuals from point to other point. Predicting taxi demand accurately and supplying the right number of taxis in the right place at the right time is very important and would lead to numerous benefits on several levels; Customers would experience a lower expected wait time, taxi companies would have more efficient resource usage by regulating the number of taxis, and drivers would receive recommendations on where to look for customers as well as a reduction in time spent roaming and queuing for customers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Elastic Search:\n",
    "We used  Elastic Search Engine to manage large size of data "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Data Information:\n",
    "<b>Source of Data:</b> Data can be downloaded from here:<br>\n",
    "https://www1.nyc.gov/site/tlc/about/tlc-trip-record-data.page.<br> \n",
    "Here, we have used 2019  data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.4 Information about Taxis:\n",
    "\n",
    "* <b>Yellow Taxi:</b> Yellow Medallion Taxicabs<br>\n",
    "These are the famous NYC yellow taxis that provide transportation exclusively through street-hails. The number of taxicabs is limited by a finite number of medallions issued by the TLC. You access this mode of transportation by standing in the street and hailing an available taxi with your hand. The pickups are not pre-arranged.<br><br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.5 Features in Dataset:\n",
    "<table>\n",
    "\t<tr>\n",
    "\t\t<th>Field Name</th>\n",
    "\t\t<th>Description</th>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>VendorID</td>\n",
    "\t\t<td>\n",
    "\t\tA code indicating the TPEP provider that provided the record. \n",
    "\t\t<ol>\n",
    "\t\t\t<li>Creative Mobile Technologies</li>\n",
    "\t\t\t<li>VeriFone Inc.</li>\n",
    "\t\t</ol>\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>tpep_pickup_datetime</td>\n",
    "\t\t<td>The date and time when the meter was engaged.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>tpep_dropoff_datetime</td>\n",
    "\t\t<td>The date and time when the meter was disengaged.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Passenger_count</td>\n",
    "\t\t<td>The number of passengers in the vehicle. This is a driver-entered value.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Trip_distance</td>\n",
    "\t\t<td>The elapsed trip distance in miles reported by the taximeter.</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>PULocationID</td>\n",
    "\t\t<td>TLC Taxi Zone in which the taximeter was engaged</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>DOLocationID</td>\n",
    "\t\t<td>TTLC Taxi Zone in which the taximeter was disengaged</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>RateCodeID</td>\n",
    "\t\t<td>The final rate code in effect at the end of the trip.\n",
    "\t\t<ol>\n",
    "\t\t\t<li> Standard rate </li>\n",
    "\t\t\t<li> JFK </li>\n",
    "\t\t\t<li> Newark </li>\n",
    "\t\t\t<li> Nassau or Westchester</li>\n",
    "\t\t\t<li> Negotiated fare </li>\n",
    "\t\t\t<li> Group ride</li>\n",
    "\t\t</ol>\n",
    "\t\t</td>\n",
    "\t</tr>\n",
    "\t<tr>\n",
    "\t\t<td>Store_and_fwd_flag</td>\n",
    "\t\t<td>This flag indicates whether the trip record was held in vehicle memory before sending to the vendor,<br\\> aka             “store and forward,” because the vehicle did not have a connection to the server.\n",
    "\t\t<br\\>Y= store and forward trip\n",
    "\t\t<br\\>N= not a store and forward trip\n",
    "\t\t<td>\n",
    "\t<tr>\n",
    "    </tr> \n",
    "       <td> Payment_type  </td>\n",
    "       <td> A numeric code signifying how the passenger paid for the trip.\n",
    "       <br\\>1= Credit card\n",
    "       <br\\>2= Cash\n",
    "       <br\\>3= No charge\n",
    "       <br\\>4= Dispute\n",
    "       <br\\>5= Unknown\n",
    "       <br\\>6= Voided trip\n",
    "       <td>    \n",
    "    <tr>\n",
    "    </tr>      \n",
    "      <td> Fare_amount </td>  \n",
    "      <td> The time-and-distance fare calculated by the meter.  \n",
    "    <tr>\n",
    "    </tr>\n",
    "      <td> Extra  </td>\n",
    "      <td> Miscellaneous extras and surcharges. Currently, this only includes<br\\>\n",
    "           the $0.50$ and $1$ rush hour and overnight charges..  \n",
    "    <tr>\n",
    "    </tr>              \n",
    "       <td> MTA_tax  </td>\n",
    "       <td> $0.50$ MTA tax that is automatically triggered based on the meteredrate in use.. \n",
    "  <tr>\n",
    "  </tr>\n",
    "        <td>Tip_amount </td>\n",
    "        <td> ip amount – This field is automatically populated for credit card\n",
    "tips. Cash tips are not included. <br\\> \n",
    "      <tr>\n",
    "    </tr>\n",
    "        <td>Tolls_amount </td>\n",
    "        <td> Total amount of all tolls paid in trip.\n",
    "    <tr>\n",
    "    </tr>\n",
    "        <td>  Total_amount </td>\n",
    "        <td> The total amount charged to passengers. Does not include cash tips. <br\\>  \n",
    "    <tr> \n",
    "    </tr>\n",
    "<table>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.6 Problem Formulation: Time Series Forecasting:\n",
    "\n",
    "Given a region and a 10min interval, we have to predict pickups.\n",
    "\n",
    "*  Every region of NYC has to be divided into 10 min interval.<br>\n",
    "\n",
    "We already know, about the pickup at time 't', we will predict the pickup at time 't+1' in the same region. Hence, this problem can be thought of as a 'Time Series Prediction' problem. It is a special case of regression problems. In short, we will use the data at time 't' to predict for time 't+1'."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.7 Performance Metric:\n",
    "*  Mean Absolute Error (MAE) \n",
    "*  Mean Squared Error(MSE)\n",
    "*  Root Mean Squared Error (RMSE)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 - Project Code:\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Operate Elasticsearch and Kibana engine:\n",
    "\n",
    "* (a):Operate Elastic search from our file location\n",
    "* (b):Operate Kibana search from our file location.<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Import Libariys:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import math\n",
    "from elasticsearch import Elasticsearch\n",
    "import json\n",
    "import warnings    \n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.use('nbagg') \n",
    "warnings.simplefilter('ignore')\n",
    "from datetime import datetime\n",
    "from datetime import timedelta\n",
    "import time \n",
    "import seaborn as sns\n",
    "from timeit import default_timer as timer\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import cross_val_score \n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn import metrics\n",
    "from numpy import mean\n",
    "from sklearn.datasets import make_classification\n",
    "from matplotlib import pyplot\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.svm import LinearSVC\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.linear_model import SGDClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 Connect to Elasticsearch server:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "es = Elasticsearch('localhost:9200')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 Feature selection:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data_from_ES (my_index,Start_index,Final_index,step):\n",
    "    col=['tpep_dropoff_datetime','tpep_pickup_datetime','trip_distance','DOLocationID',\n",
    "         'PULocationID','passenger_count']\n",
    "\n",
    "    df= pd.DataFrame(columns=col)\n",
    "    dict_index_fields = {}\n",
    "    mapping = es.indices.get_mapping(my_index) \n",
    "    dict_index_fields[my_index] = []\n",
    "    for field in mapping[my_index]['mappings']['properties']:\n",
    "        dict_index_fields[my_index].append(field) \n",
    "    j=0\n",
    "    for i in range(Start_index,Final_index,step):\n",
    "        res = es.get(index =  my_index,  id=i)\n",
    "        df.loc[j, ['tpep_dropoff_datetime']] = res['_source']['tpep_dropoff_datetime']\n",
    "        df.loc[j, ['tpep_pickup_datetime']]  = res['_source']['tpep_pickup_datetime']\n",
    "        df.loc[j, ['trip_distance']]         = res['_source']['trip_distance']\n",
    "        df.loc[j, ['DOLocationID']]          = res['_source']['DOLocationID']\n",
    "        df.loc[j, ['PULocationID']]          = res['_source']['PULocationID']\n",
    "        df.loc[j, ['passenger_count']]       = res['_source']['passenger_count']\n",
    "        j+=1\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2.5 Read data:\n",
    "1. Compin all month need in a single data fram.\n",
    "2. Delete zero trip distance value from data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done m1\n",
      "done m2\n",
      "done m3\n",
      "done m4\n",
      "done m5\n",
      "done m6\n",
      "done m7\n",
      "done m8\n",
      "done m9\n",
      "done m10\n",
      "done m11\n",
      "done m12\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>1.50</td>\n",
       "      <td>239</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 01:07:33</td>\n",
       "      <td>2019-01-01 00:52:08</td>\n",
       "      <td>1.60</td>\n",
       "      <td>48</td>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:54:36</td>\n",
       "      <td>2019-01-01 00:45:31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:35:53</td>\n",
       "      <td>2019-01-01 00:32:05</td>\n",
       "      <td>0.81</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:54:07</td>\n",
       "      <td>2019-01-01 00:49:24</td>\n",
       "      <td>0.87</td>\n",
       "      <td>239</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index tpep_dropoff_datetime tpep_pickup_datetime  trip_distance  \\\n",
       "0      0   2019-01-01 00:53:20  2019-01-01 00:46:40           1.50   \n",
       "1      1   2019-01-01 01:07:33  2019-01-01 00:52:08           1.60   \n",
       "2      2   2019-01-01 00:54:36  2019-01-01 00:45:31           1.00   \n",
       "3      3   2019-01-01 00:35:53  2019-01-01 00:32:05           0.81   \n",
       "4      4   2019-01-01 00:54:07  2019-01-01 00:49:24           0.87   \n",
       "\n",
       "   DOLocationID  PULocationID  passenger_count  \n",
       "0           239           151                1  \n",
       "1            48           230                2  \n",
       "2           261           261                1  \n",
       "3            75            75                3  \n",
       "4           239           142                1  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Read data\n",
    "start_time = time.monotonic()\n",
    "df_m1=   read_data_from_ES('m1year2019',1,7667792,760)\n",
    "print('done m1')\n",
    "df_m2=   read_data_from_ES('m2year2019',1,7019375,700)\n",
    "print('done m2')\n",
    "df_m3=   read_data_from_ES('m3year2019',1,7832545,780)\n",
    "print('done m3')\n",
    "df_m4=   read_data_from_ES('m4year2019',1,7433139,740)\n",
    "print('done m4')\n",
    "df_m5=   read_data_from_ES('m5year2019',1,7565261,750)\n",
    "print('done m5')\n",
    "df_m6=   read_data_from_ES('m6year2019',1,6941024,690)\n",
    "print('done m6')\n",
    "df_m7=   read_data_from_ES('m7year2019',1,6310419,630)\n",
    "print('done m7')\n",
    "df_m8=   read_data_from_ES('m8year2019',1,6073357,600)\n",
    "print('done m8')\n",
    "df_m9=   read_data_from_ES('m9year2019',1,6416056,640)\n",
    "print('done m9')\n",
    "df_m10= read_data_from_ES('m10year2019',1,7213891,720)\n",
    "print('done m10')\n",
    "df_m11= read_data_from_ES('m11year2019',1,6878111,680)\n",
    "print('done m11')\n",
    "df_m12= read_data_from_ES('m12year2019',1,6896317,680)\n",
    "print('done m12')\n",
    "\n",
    "# Append all data to one frame\n",
    "\n",
    "data = df_m1\n",
    "data =data.append(df_m2 , ignore_index=True)\n",
    "data =data.append(df_m3 , ignore_index=True)\n",
    "data =data.append(df_m4 , ignore_index=True)\n",
    "data =data.append(df_m5 , ignore_index=True)\n",
    "data =data.append(df_m6 , ignore_index=True)\n",
    "data =data.append(df_m7 , ignore_index=True)\n",
    "data =data.append(df_m8 , ignore_index=True)\n",
    "data =data.append(df_m9 , ignore_index=True)\n",
    "data =data.append(df_m10 ,ignore_index=True)\n",
    "data =data.append(df_m11 ,ignore_index=True)\n",
    "data =data.append(df_m12 ,ignore_index=True)\n",
    "# Remove some wrong data\n",
    "data.drop(data[data['trip_distance'] == '.00'].index , inplace=True)\n",
    "data.drop(data[data['passenger_count'] == ''].index , inplace=True)\n",
    "data.drop(data[data['passenger_count'] == '0'].index , inplace=True)\n",
    "elastic_df=data.reset_index()\n",
    "#Convert from string values to Correct value\n",
    "elastic_df['trip_distance'] = elastic_df['trip_distance'].astype(float)\n",
    "elastic_df['PULocationID'] = elastic_df['PULocationID'].astype(int)\n",
    "elastic_df['DOLocationID'] = elastic_df['DOLocationID'].astype(int)\n",
    "elastic_df['passenger_count'] = elastic_df['passenger_count'].astype(int)\n",
    "elastic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Show some important information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117172 entries, 0 to 117171\n",
      "Data columns (total 7 columns):\n",
      " #   Column                 Non-Null Count   Dtype  \n",
      "---  ------                 --------------   -----  \n",
      " 0   index                  117172 non-null  int64  \n",
      " 1   tpep_dropoff_datetime  117172 non-null  object \n",
      " 2   tpep_pickup_datetime   117172 non-null  object \n",
      " 3   trip_distance          117172 non-null  float64\n",
      " 4   DOLocationID           117172 non-null  int32  \n",
      " 5   PULocationID           117172 non-null  int32  \n",
      " 6   passenger_count        117172 non-null  int32  \n",
      "dtypes: float64(1), int32(3), int64(1), object(2)\n",
      "memory usage: 4.9+ MB\n"
     ]
    }
   ],
   "source": [
    "elastic_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>117172.000000</td>\n",
       "      <td>117172.000000</td>\n",
       "      <td>117172.000000</td>\n",
       "      <td>117172.000000</td>\n",
       "      <td>117172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>60251.085771</td>\n",
       "      <td>3.007385</td>\n",
       "      <td>161.158195</td>\n",
       "      <td>163.197462</td>\n",
       "      <td>1.597831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>34867.128466</td>\n",
       "      <td>3.902712</td>\n",
       "      <td>70.032603</td>\n",
       "      <td>65.861761</td>\n",
       "      <td>1.202960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.010000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>30043.750000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>116.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>60162.500000</td>\n",
       "      <td>1.640000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>90436.250000</td>\n",
       "      <td>3.032500</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>120720.000000</td>\n",
       "      <td>73.930000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               index  trip_distance   DOLocationID   PULocationID  \\\n",
       "count  117172.000000  117172.000000  117172.000000  117172.000000   \n",
       "mean    60251.085771       3.007385     161.158195     163.197462   \n",
       "std     34867.128466       3.902712      70.032603      65.861761   \n",
       "min         0.000000       0.010000       1.000000       1.000000   \n",
       "25%     30043.750000       1.000000     107.000000     116.000000   \n",
       "50%     60162.500000       1.640000     162.000000     162.000000   \n",
       "75%     90436.250000       3.032500     233.000000     233.000000   \n",
       "max    120720.000000      73.930000     265.000000     265.000000   \n",
       "\n",
       "       passenger_count  \n",
       "count    117172.000000  \n",
       "mean          1.597831  \n",
       "std           1.202960  \n",
       "min           1.000000  \n",
       "25%           1.000000  \n",
       "50%           1.000000  \n",
       "75%           2.000000  \n",
       "max           6.000000  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0:05:45.875000\n"
     ]
    }
   ],
   "source": [
    "end_time = time.monotonic()\n",
    "print(timedelta(seconds=end_time - start_time))\n",
    "start_time = time.monotonic()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.7 Find the reigon are exisit or not !! (all region = 265 , but Yallow Taxi zone = 57  zone only ) \n",
    "For more information see lockup taxi table in source site (i.e 17 mean name of zone in NYC , With other type of taxi operator \"Boro Taxi\")."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Empty DataFrame\n",
       "Columns: [index, tpep_dropoff_datetime, tpep_pickup_datetime, trip_distance, DOLocationID, PULocationID, passenger_count]\n",
       "Index: []"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_df.loc[elastic_df['PULocationID'] == '17']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.8 Find Trip duration and speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 2019-01-01 00:00:00  >>>  1546300800 \n",
    "def timeToUnix(t):\n",
    "    change = datetime.strptime(t,\"%Y-%m-%d %H:%M:%S\") \n",
    "    t_tuple = change.timetuple()\n",
    "    return time.mktime(t_tuple) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Calculate_time_speed():\n",
    "    pickup_time={}\n",
    "    dropoff_time={}\n",
    "    trip_duration={}\n",
    "    speed={}\n",
    "    for i in range (len(elastic_df[\"tpep_pickup_datetime\"])):\n",
    "        pickup_time[i]=timeToUnix(elastic_df[\"tpep_pickup_datetime\"][i])\n",
    "        dropoff_time[i]=timeToUnix(elastic_df['tpep_dropoff_datetime'][i])\n",
    "        trip_duration[i]=( dropoff_time[i]-pickup_time[i])/60 # divide by 60 to convert to minutes.\n",
    "        if trip_duration[i] == 0 :\n",
    "            trip_duration[i] = 0.00001\n",
    "        speed[i]=float( elastic_df['trip_distance'][i])/ (trip_duration[i]) /60 # Speed in miles/hr.\n",
    "    pickup_time= (pd.DataFrame.from_dict(pickup_time.items()))\n",
    "    pickup_time.drop([0], axis=1, inplace=True)\n",
    "    \n",
    "    dropoff_time= (pd.DataFrame.from_dict(dropoff_time.items()))\n",
    "    dropoff_time.drop([0], axis=1, inplace=True)\n",
    "    \n",
    "    trip_duration= (pd.DataFrame.from_dict(trip_duration.items()))\n",
    "    trip_duration.drop([0], axis=1, inplace=True)\n",
    "    \n",
    "    speed= (pd.DataFrame.from_dict(speed.items()))\n",
    "    speed.drop([0], axis=1, inplace=True)\n",
    "    \n",
    "    elastic_df['speed'] = np.array(speed)\n",
    "    elastic_df['trip_duration'] = np.array(trip_duration)\n",
    "    elastic_df['dropoff_time'] = np.array(dropoff_time)\n",
    "    elastic_df['pickup_time'] = np.array(pickup_time)\n",
    "    return  elastic_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_df=Calculate_time_speed()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>speed</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>pickup_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>1.50</td>\n",
       "      <td>239</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1.546297e+09</td>\n",
       "      <td>1.546296e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 01:07:33</td>\n",
       "      <td>2019-01-01 00:52:08</td>\n",
       "      <td>1.60</td>\n",
       "      <td>48</td>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>15.416667</td>\n",
       "      <td>1.546298e+09</td>\n",
       "      <td>1.546297e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:54:36</td>\n",
       "      <td>2019-01-01 00:45:31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>9.083333</td>\n",
       "      <td>1.546297e+09</td>\n",
       "      <td>1.546296e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:35:53</td>\n",
       "      <td>2019-01-01 00:32:05</td>\n",
       "      <td>0.81</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.546296e+09</td>\n",
       "      <td>1.546296e+09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:54:07</td>\n",
       "      <td>2019-01-01 00:49:24</td>\n",
       "      <td>0.87</td>\n",
       "      <td>239</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>4.716667</td>\n",
       "      <td>1.546297e+09</td>\n",
       "      <td>1.546297e+09</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index tpep_dropoff_datetime tpep_pickup_datetime  trip_distance  \\\n",
       "0      0   2019-01-01 00:53:20  2019-01-01 00:46:40           1.50   \n",
       "1      1   2019-01-01 01:07:33  2019-01-01 00:52:08           1.60   \n",
       "2      2   2019-01-01 00:54:36  2019-01-01 00:45:31           1.00   \n",
       "3      3   2019-01-01 00:35:53  2019-01-01 00:32:05           0.81   \n",
       "4      4   2019-01-01 00:54:07  2019-01-01 00:49:24           0.87   \n",
       "\n",
       "   DOLocationID  PULocationID  passenger_count     speed  trip_duration  \\\n",
       "0           239           151                1  0.003750       6.666667   \n",
       "1            48           230                2  0.001730      15.416667   \n",
       "2           261           261                1  0.001835       9.083333   \n",
       "3            75            75                3  0.003553       3.800000   \n",
       "4           239           142                1  0.003074       4.716667   \n",
       "\n",
       "   dropoff_time   pickup_time  \n",
       "0  1.546297e+09  1.546296e+09  \n",
       "1  1.546298e+09  1.546297e+09  \n",
       "2  1.546297e+09  1.546296e+09  \n",
       "3  1.546296e+09  1.546296e+09  \n",
       "4  1.546297e+09  1.546297e+09  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Data Preparation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 Time binning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For pickup\n",
    "# 1546300800 : 2019-01-01 00:00:00   (Equivalent unix time)\n",
    "# 1577836800 : 2020-01-01 00:00:00   (Equivalent unix time)\n",
    "def pickup_10min_bins(dataframe,year):\n",
    "    pickupTime =dataframe['pickup_time']\n",
    "    unixTime = [1546248880, 1577784880]\n",
    "    unix_year = unixTime[year-2019]\n",
    "    #600 = 10 min\n",
    "    time_10min_bin = [int((i - unix_year)/600) for i in pickupTime]\n",
    "    dataframe[\"pickup\"] = np.array(time_10min_bin)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For dropoff\n",
    "\n",
    "# 1546300800 : 2019-01-01 00:00:00   (Equivalent unix time)\n",
    "# 1577836800 : 2020-01-01 00:00:00   (Equivalent unix time)\n",
    "def dropoff_10min_bins(dataframe,year):\n",
    "    dropoffTime =dataframe['dropoff_time']\n",
    "    unixTime = [1546248880, 1577784880]\n",
    "    unix_year = unixTime[year-2019]\n",
    "    time_10min_bin = [int((i - unix_year)/600) for i in dropoffTime]\n",
    "    dataframe[\"dropoff\"] = np.array(time_10min_bin)\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "elastic_df=pickup_10min_bins(elastic_df,2019)\n",
    "elastic_df=dropoff_10min_bins(elastic_df,2019)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>tpep_dropoff_datetime</th>\n",
       "      <th>tpep_pickup_datetime</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>passenger_count</th>\n",
       "      <th>speed</th>\n",
       "      <th>trip_duration</th>\n",
       "      <th>dropoff_time</th>\n",
       "      <th>pickup_time</th>\n",
       "      <th>pickup</th>\n",
       "      <th>dropoff</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>2019-01-01 00:53:20</td>\n",
       "      <td>2019-01-01 00:46:40</td>\n",
       "      <td>1.50</td>\n",
       "      <td>239</td>\n",
       "      <td>151</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003750</td>\n",
       "      <td>6.666667</td>\n",
       "      <td>1.546297e+09</td>\n",
       "      <td>1.546296e+09</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2019-01-01 01:07:33</td>\n",
       "      <td>2019-01-01 00:52:08</td>\n",
       "      <td>1.60</td>\n",
       "      <td>48</td>\n",
       "      <td>230</td>\n",
       "      <td>2</td>\n",
       "      <td>0.001730</td>\n",
       "      <td>15.416667</td>\n",
       "      <td>1.546298e+09</td>\n",
       "      <td>1.546297e+09</td>\n",
       "      <td>79</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>2019-01-01 00:54:36</td>\n",
       "      <td>2019-01-01 00:45:31</td>\n",
       "      <td>1.00</td>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>1</td>\n",
       "      <td>0.001835</td>\n",
       "      <td>9.083333</td>\n",
       "      <td>1.546297e+09</td>\n",
       "      <td>1.546296e+09</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>2019-01-01 00:35:53</td>\n",
       "      <td>2019-01-01 00:32:05</td>\n",
       "      <td>0.81</td>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>3</td>\n",
       "      <td>0.003553</td>\n",
       "      <td>3.800000</td>\n",
       "      <td>1.546296e+09</td>\n",
       "      <td>1.546296e+09</td>\n",
       "      <td>77</td>\n",
       "      <td>78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>2019-01-01 00:54:07</td>\n",
       "      <td>2019-01-01 00:49:24</td>\n",
       "      <td>0.87</td>\n",
       "      <td>239</td>\n",
       "      <td>142</td>\n",
       "      <td>1</td>\n",
       "      <td>0.003074</td>\n",
       "      <td>4.716667</td>\n",
       "      <td>1.546297e+09</td>\n",
       "      <td>1.546297e+09</td>\n",
       "      <td>79</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index tpep_dropoff_datetime tpep_pickup_datetime  trip_distance  \\\n",
       "0      0   2019-01-01 00:53:20  2019-01-01 00:46:40           1.50   \n",
       "1      1   2019-01-01 01:07:33  2019-01-01 00:52:08           1.60   \n",
       "2      2   2019-01-01 00:54:36  2019-01-01 00:45:31           1.00   \n",
       "3      3   2019-01-01 00:35:53  2019-01-01 00:32:05           0.81   \n",
       "4      4   2019-01-01 00:54:07  2019-01-01 00:49:24           0.87   \n",
       "\n",
       "   DOLocationID  PULocationID  passenger_count     speed  trip_duration  \\\n",
       "0           239           151                1  0.003750       6.666667   \n",
       "1            48           230                2  0.001730      15.416667   \n",
       "2           261           261                1  0.001835       9.083333   \n",
       "3            75            75                3  0.003553       3.800000   \n",
       "4           239           142                1  0.003074       4.716667   \n",
       "\n",
       "   dropoff_time   pickup_time  pickup  dropoff  \n",
       "0  1.546297e+09  1.546296e+09      79       79  \n",
       "1  1.546298e+09  1.546297e+09      79       81  \n",
       "2  1.546297e+09  1.546296e+09      79       79  \n",
       "3  1.546296e+09  1.546296e+09      77       78  \n",
       "4  1.546297e+09  1.546297e+09      79       79  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "elastic_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data In figures:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Pickup time Vs passenger count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic_df.plot(x='pickup_time', y='passenger_count', kind=\"bar\")\n",
    "#plt.xlabel(\"pickup time\",fontsize=12)\n",
    "#plt.ylabel(\"passenger count\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('data1')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2 Index Vs passenger count:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic_df.plot(x='index', y='passenger_count', kind=\"bar\")\n",
    "#plt.xlabel(\"index\",fontsize=12)\n",
    "#plt.ylabel(\"passenger count\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('data2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3 Index Vs trip distance:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic_df.plot(x='index', y='trip_distance', kind=\"bar\")\n",
    "#plt.xlabel(\"index\",fontsize=12)\n",
    "#plt.ylabel(\"trip distance\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('data3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.4 Index Vs trip duration:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#fig = plt.figure()\n",
    "#elastic_df.plot(x='index', y='trip_duration', kind=\"bar\")\n",
    "#plt.xlabel(\"index\",fontsize=12)\n",
    "#plt.ylabel(\"trip duration\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('data4')\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.5 Index Vs PULocationID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic_df.plot(x='index', y='PULocationID', kind=\"bar\")\n",
    "#plt.xlabel(\"index\",fontsize=12)\n",
    "#plt.ylabel(\"PULocationID\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('data5')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.6 Index Vs POLocationID:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic_df.plot(x='index', y='DOLocationID', kind=\"bar\")\n",
    "#plt.xlabel(\"index\",fontsize=12)\n",
    "#plt.ylabel(\"DOLocationID\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('data6')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.7 Index Vs speed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "#elastic_df.plot(x='index', y='speed', kind=\"bar\")\n",
    "#plt.xlabel(\"index\",fontsize=12)\n",
    "#plt.ylabel(\"Speed\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('data7')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.8 Grid relations between 'PULocationID',  'DOLocationID',   'pickup',  'passenger_count':"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>pickup</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>151</td>\n",
       "      <td>239</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>230</td>\n",
       "      <td>48</td>\n",
       "      <td>79</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>261</td>\n",
       "      <td>261</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>75</td>\n",
       "      <td>75</td>\n",
       "      <td>77</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>142</td>\n",
       "      <td>239</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PULocationID  DOLocationID  pickup  passenger_count\n",
       "0           151           239      79                1\n",
       "1           230            48      79                2\n",
       "2           261           261      79                1\n",
       "3            75            75      77                3\n",
       "4           142           239      79                1"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data2019 = elastic_df[['PULocationID','DOLocationID','pickup','passenger_count']]\n",
    "new_data2019.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 117172 entries, 0 to 117171\n",
      "Data columns (total 4 columns):\n",
      " #   Column           Non-Null Count   Dtype\n",
      "---  ------           --------------   -----\n",
      " 0   PULocationID     117172 non-null  int32\n",
      " 1   DOLocationID     117172 non-null  int32\n",
      " 2   pickup           117172 non-null  int32\n",
      " 3   passenger_count  117172 non-null  int32\n",
      "dtypes: int32(4)\n",
      "memory usage: 1.8 MB\n"
     ]
    }
   ],
   "source": [
    "new_data2019.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PULocationID</th>\n",
       "      <th>DOLocationID</th>\n",
       "      <th>pickup</th>\n",
       "      <th>passenger_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>117172.000000</td>\n",
       "      <td>117172.000000</td>\n",
       "      <td>117172.000000</td>\n",
       "      <td>117172.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>163.197462</td>\n",
       "      <td>161.158195</td>\n",
       "      <td>26186.625730</td>\n",
       "      <td>1.597831</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>65.861761</td>\n",
       "      <td>70.032603</td>\n",
       "      <td>15174.628253</td>\n",
       "      <td>1.202960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>1.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>19.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>116.000000</td>\n",
       "      <td>107.000000</td>\n",
       "      <td>12975.750000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>162.000000</td>\n",
       "      <td>162.000000</td>\n",
       "      <td>26013.500000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>233.000000</td>\n",
       "      <td>233.000000</td>\n",
       "      <td>39273.000000</td>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>265.000000</td>\n",
       "      <td>265.000000</td>\n",
       "      <td>56519.000000</td>\n",
       "      <td>6.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        PULocationID   DOLocationID         pickup  passenger_count\n",
       "count  117172.000000  117172.000000  117172.000000    117172.000000\n",
       "mean      163.197462     161.158195   26186.625730         1.597831\n",
       "std        65.861761      70.032603   15174.628253         1.202960\n",
       "min         1.000000       1.000000      19.000000         1.000000\n",
       "25%       116.000000     107.000000   12975.750000         1.000000\n",
       "50%       162.000000     162.000000   26013.500000         1.000000\n",
       "75%       233.000000     233.000000   39273.000000         2.000000\n",
       "max       265.000000     265.000000   56519.000000         6.000000"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new_data2019.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(new_data2019)\n",
    "#plt.savefig('data8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#sns.pairplot(new_data2019, vars = ['PULocationID','DOLocationID','pickup','passenger_count'], hue ='passenger_count', palette='Dark2')\n",
    "#plt.savefig('data9')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(new_data2019, vars =  ['PULocationID','DOLocationID','pickup','passenger_count'], hue ='passenger_count', hue_order = [1.0, 0.0])\n",
    "#plt.savefig('data10')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(new_data2019,vars = ['PULocationID','DOLocationID','pickup','passenger_count'], hue ='passenger_count', kind = 'reg')\n",
    "#plt.savefig('data11')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5 - Define Training and Prediction data: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = new_data2019[['PULocationID','DOLocationID','pickup']]\n",
    "y = new_data2019[['passenger_count']]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  5.1 Splitting data, 20% for Testing and 80% for Training :"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# 20% for Final testing \n",
    "x_train, x_test, y_train, y_test = train_test_split(x, y, test_size=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#  6 - Cross-validation (Out-of-sample testing):\n",
    "Cross-validation is a statistical method used to estimate the skill of machine learning models.\n",
    "It is commonly used in applied machine learning to compare and select a model for a given predictive modeling problem because it is easy to understand, easy to implement, and results in skill estimates that generally have a lower bias than other methods.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6.1 Choose the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# retrieve the model to be evaluate\n",
    "def get_model1():\n",
    "    model=LogisticRegression()\n",
    "    return model\n",
    "def get_model2():\n",
    "    model=RandomForestClassifier()\n",
    "    return model\n",
    "def get_model3():\n",
    "    model=LinearSVC()\n",
    "    return model\n",
    "def get_model4():\n",
    "    model=MLPClassifier()\n",
    "    return model\n",
    "def get_model5():\n",
    "    model=SGDClassifier()\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6.2 Evaluate the model:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal test condition for  Logistic Regression "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model using a given test condition\n",
    "def evaluate_model1(cv):\n",
    "    # get the model\n",
    "    model = get_model1()\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score( model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    "# calculate the ideal test condition\n",
    "ideal1, _, _ = evaluate_model1(KFold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal test condition for  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model using a given test condition\n",
    "def evaluate_model2(cv):\n",
    "    # get the model\n",
    "    model = get_model2()\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score( model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    "# calculate the ideal test condition\n",
    "ideal2, _, _ = evaluate_model2(KFold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal test condition for Linear Support vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model using a given test condition\n",
    "def evaluate_model3(cv):\n",
    "    # get the model\n",
    "    model = get_model3()\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score( model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    "# calculate the ideal test condition\n",
    "ideal3, _, _ = evaluate_model3(KFold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal test condition for Nural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model using a given test condition\n",
    "def evaluate_model4(cv):\n",
    "    # get the model\n",
    "    model = get_model4()\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score( model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    "# calculate the ideal test condition\n",
    "ideal4, _, _ = evaluate_model4(KFold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ideal test condition for Stochastic Gradient Descent  Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# evaluate the model using a given test condition\n",
    "def evaluate_model5(cv):\n",
    "    # get the model\n",
    "    model = get_model5()\n",
    "    # evaluate the model\n",
    "    scores = cross_val_score( model, x_train, y_train, scoring='accuracy', cv=cv, n_jobs=-1)\n",
    "    # return scores\n",
    "    return mean(scores), scores.min(), scores.max()\n",
    "# calculate the ideal test condition\n",
    "ideal5, _, _ = evaluate_model5(KFold())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  6.3 K-fold cross validation:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Find the best k from k=2 to k=31, k refers to the number of groups that a given data sample is to be split into.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold for  logistic Regression Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs ,min1,max1= list(),list(),list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluate_model1(cv)\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    min1.append(k_min)\n",
    "    max1.append(k_max)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "    df1= pd.DataFrame()\n",
    "df1['folds']=folds\n",
    "df1['accuracy_mean']=means\n",
    "df1['accuracy_min']=min1\n",
    "df1['accuracy_max']=max1\n",
    "df1['accuracy_mins']=mins\n",
    "df1['accuracy_maxs']=maxs\n",
    "# line plot of k mean values with min/max error bars\n",
    "#plt.figure()\n",
    "#pyplot.errorbar(df1['folds'], df1['accuracy_mean'], yerr=[df1['accuracy_mins'],df1['accuracy_maxs']], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "#pyplot.plot(df1['folds'], [ideal1 for _ in range(len(folds))], color='r')\n",
    "#plt.xlabel(\"K-Folds\",fontsize=12)\n",
    "#plt.title(\"K-Fold for logistic Regression Classifier\")\n",
    "#plt.ylabel(\"accuracy\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('Kfold1')\n",
    "CF1=df1.loc[df1['accuracy_max'] == max(df1['accuracy_max'])]\n",
    "CF1['Ideal']=ideal1 \n",
    "CF1['Model']='Logistic Regression '\n",
    "CF=CF1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold for  Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs ,min1,max1= list(),list(),list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluate_model2(cv)\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    min1.append(k_min)\n",
    "    max1.append(k_max)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "    df1= pd.DataFrame()\n",
    "df1['folds']=folds\n",
    "df1['accuracy_mean']=means\n",
    "df1['accuracy_min']=min1\n",
    "df1['accuracy_max']=max1\n",
    "df1['accuracy_mins']=mins\n",
    "df1['accuracy_maxs']=maxs\n",
    "\n",
    "# line plot of k mean values with min/max error bars\n",
    "#plt.figure()\n",
    "#pyplot.errorbar(df1['folds'], df1['accuracy_mean'], yerr=[df1['accuracy_mins'],df1['accuracy_maxs']], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "#pyplot.plot(df1['folds'], [ideal2 for _ in range(len(folds))], color='r')\n",
    "#plt.xlabel(\"K-Folds\",fontsize=12)\n",
    "#plt.title(\"K-Fold for Random Forest Classifierr\")\n",
    "#plt.ylabel(\"accuracy\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('Kfold2')\n",
    "CF1=df1.loc[df1['accuracy_max'] == max(df1['accuracy_max'])]\n",
    "CF1['Ideal']=ideal2 \n",
    "CF1['Model']='Random Forest '\n",
    "CF=CF.append(CF1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  K-Fold for  Linear Support Vector Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs ,min1,max1= list(),list(),list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluate_model3(cv)\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    min1.append(k_min)\n",
    "    max1.append(k_max)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "    df1= pd.DataFrame()\n",
    "df1['folds']=folds\n",
    "df1['accuracy_mean']=means\n",
    "df1['accuracy_min']=min1\n",
    "df1['accuracy_max']=max1\n",
    "df1['accuracy_mins']=mins\n",
    "df1['accuracy_maxs']=maxs\n",
    "# line plot of k mean values with min/max error bars\n",
    "#plt.figure()\n",
    "#pyplot.errorbar(df1['folds'], df1['accuracy_mean'], yerr=[df1['accuracy_mins'],df1['accuracy_maxs']], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "#pyplot.plot(df1['folds'], [ideal3 for _ in range(len(folds))], color='r')\n",
    "#plt.xlabel(\"K-Folds\",fontsize=12)\n",
    "#plt.title(\"K-Fold for Linear Support Vector Classifier\")\n",
    "#plt.ylabel(\"accuracy\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('Kfold3')\n",
    "CF1=df1.loc[df1['accuracy_max'] == max(df1['accuracy_max'])]\n",
    "CF1['Ideal']=ideal3\n",
    "CF1['Model']='Linear Support Vector'\n",
    "CF=CF.append(CF1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold for  Nural Network  Classifier "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs ,min1,max1= list(),list(),list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluate_model4(cv)\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    min1.append(k_min)\n",
    "    max1.append(k_max)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "    df1= pd.DataFrame()\n",
    "df1['folds']=folds\n",
    "df1['accuracy_mean']=means\n",
    "df1['accuracy_min']=min1\n",
    "df1['accuracy_max']=max1\n",
    "df1['accuracy_mins']=mins\n",
    "df1['accuracy_maxs']=maxs\n",
    "\n",
    "# line plot of k mean values with min/max error bars\n",
    "#plt.figure()\n",
    "#pyplot.errorbar(df1['folds'], df1['accuracy_mean'], yerr=[df1['accuracy_mins'],df1['accuracy_maxs']], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "#pyplot.plot(df1['folds'], [ideal4 for _ in range(len(folds))], color='r')\n",
    "#plt.xlabel(\"K-Folds\",fontsize=12)\n",
    "#plt.title(\"K-Fold for Nural Network Classifier\")\n",
    "#plt.ylabel(\"accuracy\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('Kfold4')\n",
    "CF1=df1.loc[df1['accuracy_max'] == max(df1['accuracy_max'])]\n",
    "CF1['Ideal']=ideal4\n",
    "CF1['Model']='Nural Network'\n",
    "CF=CF.append(CF1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### K-Fold for  Stochastic Gradient Descent  Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define folds to test\n",
    "folds = range(2,31)\n",
    "# record mean and min/max of each set of results\n",
    "means, mins, maxs ,min1,max1= list(),list(),list(),list(),list()\n",
    "# evaluate each k value\n",
    "for k in folds:\n",
    "    # define the test condition\n",
    "    cv = KFold(n_splits=k, shuffle=True, random_state=1)\n",
    "    # evaluate k value\n",
    "    k_mean, k_min, k_max = evaluate_model5(cv)\n",
    "    # store mean accuracy\n",
    "    means.append(k_mean)\n",
    "    min1.append(k_min)\n",
    "    max1.append(k_max)\n",
    "    # store min and max relative to the mean\n",
    "    mins.append(k_mean - k_min)\n",
    "    maxs.append(k_max - k_mean)\n",
    "    df1= pd.DataFrame()\n",
    "df1['folds']=folds\n",
    "df1['accuracy_mean']=means\n",
    "df1['accuracy_min']=min1\n",
    "df1['accuracy_max']=max1\n",
    "df1['accuracy_mins']=mins\n",
    "df1['accuracy_maxs']=maxs\n",
    "#plt.figure()\n",
    "# line plot of k mean values with min/max error bars\n",
    "#pyplot.errorbar(df1['folds'], df1['accuracy_mean'], yerr=[df1['accuracy_mins'],df1['accuracy_maxs']], fmt='o')\n",
    "# plot the ideal case in a separate color\n",
    "#pyplot.plot(df1['folds'], [ideal5 for _ in range(len(folds))], color='r')\n",
    "#plt.xlabel(\"K-Folds\",fontsize=12)\n",
    "#plt.title(\"K-Fold for Stochastic Gradient Descent Classifier\")\n",
    "#plt.ylabel(\"accuracy\",fontsize=12)\n",
    "#plt.autoscale(True, 'both', True)\n",
    "#plt.savefig('Kfold5')\n",
    "CF1=df1.loc[df1['accuracy_max'] == max(df1['accuracy_max'])]\n",
    "CF1['Ideal']=ideal5\n",
    "CF1['Model']='Stochastic Gradient Descent'\n",
    "CF=CF.append(CF1, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cross Validation Results "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Best K value for K-fold for each  model \n",
    "* And best accuracy of model depend on K value \n",
    "* Result of Ideal Test conditon  for each model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "CF.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The Best Select model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CF['Model'][CF.index[CF['Ideal'] == max(CF['Ideal'])]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We calculated and select best model depend on Cross validation result , but we apply all model to see the result and know how to build each classifier and check our calculation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7 - Prediction models\n",
    "\n",
    "Machine learning is computing technology that uses artificial intelligence tools to develop systems that learn from data,\n",
    "rather than simply performing programmed instructions.\n",
    "Machine learning is now widely used by researchers and industry analysts to build predictive models from a wide variety of data. \n",
    "As models are fed new data, they are able to independently adapt. They can learn from historical patterns and computations\n",
    "to produce reliable predictions and results.\n",
    "In this part we used three techniques to build our taxi demand prediction model.\n",
    "Linear Regression\n",
    "Nural Network model\n",
    "Support Vector Machines\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1- Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Logistic_Regression(x_train, x_test, y_train, y_test):\n",
    "    start_t = timer()\n",
    "    model = LogisticRegression()\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    end_t = timer()\n",
    "    time_t = (end_t - start_t)\n",
    "    print (\"Total time for Logistic Regression\", time_t)\n",
    "    MAE=metrics.mean_absolute_error(y_test, predictions)\n",
    "    MSE=metrics.mean_squared_error(y_test, predictions)\n",
    "    RMSE=np.sqrt(metrics.mean_squared_error(y_test, predictions))\n",
    "    #print(model.coef_)\n",
    "    #print(model.intercept_)\n",
    "    #plt.scatter(y_test, predictions)\n",
    "    #plt.hist(y_test - predictions)\n",
    "    #plt.show()\n",
    "    return MAE, MSE, RMSE, predictions\n",
    "LRegM=Logistic_Regression(x_train, x_test, y_train, y_test)\n",
    "LogR=LRegM[0:3]\n",
    "print (LogR)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.2- Random Forest Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Random_Forest_Classifier(x_train, x_test, y_train, y_test):\n",
    "    start_t = timer()\n",
    "    model = RandomForestClassifier()\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    end_t = timer()\n",
    "    time_t = (end_t - start_t)\n",
    "    print (\"Total time for Random Forest Classifier\", time_t)\n",
    "    MAE=metrics.mean_absolute_error(y_test, predictions)\n",
    "    MSE=metrics.mean_squared_error(y_test, predictions)\n",
    "    RMSE=np.sqrt(metrics.mean_squared_error(y_test, predictions))\n",
    "    #print(model.coef_)\n",
    "    #print(model.intercept_)\n",
    "    #plt.scatter(y_test, predictions)\n",
    "    #plt.hist(y_test - predictions)\n",
    "    #plt.show()\n",
    "    return MAE, MSE, RMSE, predictions\n",
    "RFC=Random_Forest_Classifier(x_train, x_test, y_train, y_test)\n",
    "RF=RFC[0:3]\n",
    "print (RF)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.3- Linear Support Vector Machine"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Linear_SVC(x_train, x_test, y_train, y_test):\n",
    "    start_t = timer()\n",
    "    model = LinearSVC()\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    end_t = timer()\n",
    "    time_t = (end_t - start_t)\n",
    "    print (\"Total time for Linear Support vector  Classifier\", time_t)\n",
    "    MAE=metrics.mean_absolute_error(y_test, predictions)\n",
    "    MSE=metrics.mean_squared_error(y_test, predictions)\n",
    "    RMSE=np.sqrt(metrics.mean_squared_error(y_test, predictions))\n",
    "    #print(model.coef_)\n",
    "    #print(model.intercept_)\n",
    "    #plt.scatter(y_test, predictions)\n",
    "    #plt.hist(y_test - predictions)\n",
    "    #plt.show()\n",
    "    return MAE, MSE, RMSE, predictions\n",
    "LSVC=Linear_SVC(x_train, x_test, y_train, y_test)\n",
    "LSV=LSVC[0:3]\n",
    "print (LSV)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.4- Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def neural_network(x_train, x_test, y_train, y_test):\n",
    "    start_t = timer()\n",
    "    model = MLPClassifier()\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    end_t = timer()\n",
    "    time_t = (end_t - start_t)\n",
    "    print (\"Total time for neural network  Classifier\", time_t)\n",
    "    MAE=metrics.mean_absolute_error(y_test, predictions)\n",
    "    MSE=metrics.mean_squared_error(y_test, predictions)\n",
    "    RMSE=np.sqrt(metrics.mean_squared_error(y_test, predictions))\n",
    "    #print(model.coef_)\n",
    "    #print(model.intercept_)\n",
    "    #plt.scatter(y_test, predictions)\n",
    "    #plt.hist(y_test - predictions)\n",
    "    #plt.show()\n",
    "    return MAE, MSE, RMSE, predictions\n",
    "NNM=neural_network(x_train, x_test, y_train, y_test)\n",
    "NN=NNM[0:3]\n",
    "print (NN)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.5- Stochastic Gradient Descent"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def SGD_Classifier(x_train, x_test, y_train, y_test):\n",
    "    start_t = timer()\n",
    "    model = SGDClassifier()\n",
    "    model.fit(x_train, y_train)\n",
    "    predictions = model.predict(x_test)\n",
    "    end_t = timer()\n",
    "    time_t = (end_t - start_t)\n",
    "    print (\"Total time for stochastic gradient descent  Classifier\", time_t)\n",
    "    MAE=metrics.mean_absolute_error(y_test, predictions)\n",
    "    MSE=metrics.mean_squared_error(y_test, predictions)\n",
    "    RMSE=np.sqrt(metrics.mean_squared_error(y_test, predictions))\n",
    "    #print(model.coef_)\n",
    "    #print(model.intercept_)\n",
    "    #plt.scatter(y_test, predictions)\n",
    "    #plt.hist(y_test - predictions)\n",
    "    #plt.show()\n",
    "    return MAE, MSE, RMSE, predictions\n",
    "SGDM=SGD_Classifier(x_train, x_test, y_train, y_test)\n",
    "SGD=SGDM[0:3]\n",
    "print (SGD)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8 - Comparison between model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c1=['Mean Absolute Error (MAE)','Mean Squared Error (MSE)','Root Mean Squared Error (RMSE)']\n",
    "#Error = pd.DataFrame({'Error':c1,'Linear regression model':LRM,'Nural Network model ':NN,'Support Vector Machines':SVM})\n",
    "Error = pd.DataFrame({'Error':c1,'Logistic Regression':LogR,'Random Forest Classifier':RF,\n",
    "                      'Linear Support vector':LSV,'Neural Network':NN,'stochastic gradient descent':SGD})\n",
    "Error.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Error.plot(x='Error', y=['Logistic Regression','Random Forest Classifier','Linear Support vector',\n",
    "                         'Neural Network','stochastic gradient descent'], kind=\"barh\")\n",
    "plt.xlabel('Error',fontsize=12)\n",
    "plt.title(\"Comparison between  five model\",fontsize=14)\n",
    "plt.ylabel(\"Error mesarment Type\",fontsize=12)\n",
    "plt.autoscale(True, 'both', True)\n",
    "plt.savefig('result1')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end_time = time.monotonic() \n",
    "print(timedelta(seconds=end_time-start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# From the result the best model are Nural Network model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  After reading and training data of different sizes, starting from thousand samples to five million samples, it was found that the result did not improve when increasing the size of data more than million and a half samples,  and also the results of the cross-validation agreed with the results of the training model.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
